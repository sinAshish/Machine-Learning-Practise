{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ashish/Machine-Learning-Practise/Deep Learning Challenge 2\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashish/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import  to_categorical\n",
    "from keras_tqdm import TQDMNotebookCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load training and test data csv files\n",
    "train_data = pd.read_csv('csv/train.csv')\n",
    "test_data = pd.read_csv('csv/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>view_position</th>\n",
       "      <th>image_name</th>\n",
       "      <th>detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>scan_0000.png</td>\n",
       "      <td>class_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_1</td>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>scan_0001.png</td>\n",
       "      <td>class_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_10</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>scan_00010.png</td>\n",
       "      <td>class_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_1000</td>\n",
       "      <td>64</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>scan_0001000.png</td>\n",
       "      <td>class_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_10000</td>\n",
       "      <td>33</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>scan_00010000.png</td>\n",
       "      <td>class_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_id  age gender  view_position         image_name detected\n",
       "0      id_0   45      M              0      scan_0000.png  class_3\n",
       "1      id_1   57      F              0      scan_0001.png  class_3\n",
       "2     id_10   58      M              0     scan_00010.png  class_3\n",
       "3   id_1000   64      M              0   scan_0001000.png  class_6\n",
       "4  id_10000   33      M              1  scan_00010000.png  class_3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>view_position</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_100</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>scan_000100.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_10002</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>scan_00010002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_10005</td>\n",
       "      <td>56</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>scan_00010005.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_10008</td>\n",
       "      <td>41</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>scan_00010008.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_10009</td>\n",
       "      <td>56</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>scan_00010009.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_id  age gender  view_position         image_name\n",
       "0    id_100   47      M              0    scan_000100.png\n",
       "1  id_10002   28      M              0  scan_00010002.png\n",
       "2  id_10005   56      F              0  scan_00010005.png\n",
       "3  id_10008   41      M              1  scan_00010008.png\n",
       "4  id_10009   56      F              1  scan_00010009.png"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>view_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18577.000000</td>\n",
       "      <td>18577.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>47.972601</td>\n",
       "      <td>0.573343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.741076</td>\n",
       "      <td>0.494605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>414.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  view_position\n",
       "count  18577.000000   18577.000000\n",
       "mean      47.972601       0.573343\n",
       "std       16.741076       0.494605\n",
       "min        2.000000       0.000000\n",
       "25%       36.000000       0.000000\n",
       "50%       50.000000       1.000000\n",
       "75%       60.000000       1.000000\n",
       "max      414.000000       1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>view_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12386.000000</td>\n",
       "      <td>12386.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48.028984</td>\n",
       "      <td>0.579445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.660680</td>\n",
       "      <td>0.493668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>152.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  view_position\n",
       "count  12386.000000   12386.000000\n",
       "mean      48.028984       0.579445\n",
       "std       16.660680       0.493668\n",
       "min        1.000000       0.000000\n",
       "25%       36.000000       0.000000\n",
       "50%       50.000000       1.000000\n",
       "75%       60.000000       1.000000\n",
       "max      152.000000       1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_3', 'class_6', 'class_8', 'class_7', 'class_4', 'class_5',\n",
       "       'class_10', 'class_11', 'class_1', 'class_12', 'class_13',\n",
       "       'class_2', 'class_14', 'class_9'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.detected.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.detected.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7wAAAGuCAYAAACzwgqOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ/r/AQ9bnRejS6lxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f52ece20a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "detected_count=train_data.detected.value_counts()\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.barplot(x=detected_count.index,y=detected_count.values,alpha=0.9)\n",
    "plt.xlabel('Detected Labels')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ashish/Machine-Learning-Practise/Deep Learning Challenge 2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOURCE = 'train_'\n",
    "DEST = 'train128'\n",
    "IMG_SIZE=128\n",
    "X_train=[]\n",
    "def save_images(SOURCE,DEST,IMG_SIZE):\n",
    "    for img_name in tqdm(train_data['image_name'].values):\n",
    "        img_path = os.path.join(SOURCE,img_name)\n",
    "        img=cv2.imread(img_path,cv2.IMREAD_COLOR)\n",
    "        img=cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n",
    "        #cv2.imwrite(os.path.join(os.getcwd(),DEST,img_path),img)\n",
    "        #cv2.waitKey(0)\n",
    "        #temp_img=image.load_img(img_path)\n",
    "        X_train.append(img)\n",
    "        del img\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18577/18577 [04:37<00:00, 66.83it/s]\n"
     ]
    }
   ],
   "source": [
    "save_images(SOURCE,DEST,IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_list=train_data['detected'].tolist()\n",
    "class_dict={name:count+1 for count,name in enumerate(set(class_list))}\n",
    "y_train = [class_dict[k] for k in class_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making  Training Output Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transfer learning with VGG16 \n",
    "model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train,np.float32)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18577, 128, 128, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 15)                2101263   \n",
      "=================================================================\n",
      "Total params: 16,815,951\n",
      "Trainable params: 16,815,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## set model architechture \n",
    "add_model = Sequential()\n",
    "add_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "add_model.add(Dense(256, activation='relu'))\n",
    "add_model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "model = Model(inputs=model.input, outputs=add_model(model.output))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=30, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1, \n",
    "        horizontal_flip=True)\n",
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "280/580 [=============>................] - ETA: 10:43:26 - loss: 2.2023 - acc: 0.3079"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e3574b89005a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m/home/ashish/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ashish/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2175\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2176\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ashish/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1847\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1849\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ashish/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ashish/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ashish/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ashish/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ashish/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ashish/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32 # tune it\n",
    "epochs = 50 # increase it lb:0.40856(50 epochs), 0.27101 (5 epochs)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "    steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_img = []\n",
    "SOURCE='test_'\n",
    "def save_images(SOURCE,IMG_SIZE):\n",
    "    for img_name in tqdm(test_data['image_name'].values):\n",
    "        img_path = os.path.join(SOURCE,img_name)\n",
    "        img=cv2.imread(img_path,cv2.IMREAD_COLOR)\n",
    "        img=cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n",
    "        #cv2.imwrite(os.path.join(os.getcwd(),DEST,img_path),img)\n",
    "        #cv2.waitKey(0)\n",
    "        #temp_img=image.load_img(img_path)\n",
    "        test_img.append(img)\n",
    "        del img\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12386/12386 [04:59<00:00, 41.32it/s]\n"
     ]
    }
   ],
   "source": [
    "save_images('test_',128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test=np.array(test_img,np.float32)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## predict test data\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
